{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "279828db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "705e35a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_1 = pd.read_csv('Data/Raw-Queried/Tesla-general-10K')\n",
    "tesla_2 = pd.read_csv('Data/Raw-Queried/Tesla-General-20K')\n",
    "tesla_3 = pd.read_csv('Data/Raw-Queried/Tesla-General-6K')\n",
    "tesla_4 = pd.read_csv('Data/Raw-Queried/Tesla-General-15K')\n",
    "tesla_5 = pd.read_csv('Data/Raw-Queried/ElectricCars-General-10k')\n",
    "tesla_6 = pd.read_csv('Data/Raw-Queried/Tesla-AI-1K')\n",
    "tesla_7 = pd.read_csv('Data/Raw-Queried/Tesla-AutoPilot-1k')\n",
    "tesla_8 = pd.read_csv('Data/Raw-Queried/Tesla-Batteries-1k')\n",
    "tesla_9 = pd.read_csv('Data/Raw-Queried/Tesla-Batterys-1K')\n",
    "tesla_10 = pd.read_csv('Data/Raw-Queried/Tesla-bot-1.5k')\n",
    "tesla_11 = pd.read_csv('Data/Raw-Queried/Tesla-Cars-1K')\n",
    "tesla_12 = pd.read_csv('Data/Raw-Queried/Tesla-cars-6K')\n",
    "tesla_13 = pd.read_csv('Data/Raw-Queried/Tesla-Production-1K')\n",
    "tesla_14 = pd.read_csv('Data/Raw-Queried/Tesla-solar-1K')\n",
    "tesla_15 = pd.read_csv('Data/Raw-Queried/Tesla-stock-10k')\n",
    "tesla_16 = pd.read_csv('Data/Raw-Queried/Tesla-truck-.5k')\n",
    "tesla_17 = pd.read_csv('Data/Raw-Queried/Tesla-workers-1K')\n",
    "tesla_18 = pd.read_csv('Data/Raw-Queried/Tesla-working_conds-.2K')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac92c24",
   "metadata": {},
   "source": [
    "### Function to turn all DataFrames from files into Series with User ID as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c81b4915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to turn 2 column df from csv files to 1 column series with user ID as index\n",
    "\n",
    "def df_to_series(df):\n",
    "    step1 = df.set_index('Unnamed: 0')\n",
    "    step2 = step1.squeeze()\n",
    "    return step2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a52e7",
   "metadata": {},
   "source": [
    "### Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "accfb77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Series_Preprocessor(tweet):\n",
    "    stopWords = stopwords.words('english')\n",
    "    ps = PorterStemmer()\n",
    "    wnl = WordNetLemmatizer()\n",
    "\n",
    "        # helper function to change nltk's part of speech tagging to a wordnet format.\n",
    "    def pos_tagger(nltk_tag):\n",
    "        if nltk_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif nltk_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif nltk_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif nltk_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:         \n",
    "            return None\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #       Lowercase all \n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    #       Removing @ handles, links-- strip whitespace breaks and tabs\n",
    "    tweet = re.sub(r\"@\\w+|http\\S+\", \"\", tweet).strip().replace(\"\\r\", \"\").replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    \n",
    "    \n",
    "    #       Tokenize,make list of words, removing punctuation and stopwords\n",
    "    tweet = [x for x in word_tokenize(tweet) if ((x.isalpha()) & (x not in stopWords)) ]\n",
    "    \n",
    "    \n",
    "#   Map part of speech tags to words and use words/tags to lemmatize accuratley\n",
    "    tweet = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tag(tweet))) \n",
    "    tweet = \" \".join([wnl.lemmatize(x[0], x[1]) for x in tweet if x[1] is not None])\n",
    "\n",
    "\n",
    "    return tweet "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f4535f",
   "metadata": {},
   "source": [
    "### Applying Function to set all User IDs as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45063dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_1 = df_to_series(tesla_1)\n",
    "tesla_2 = df_to_series(tesla_2)\n",
    "tesla_3 = df_to_series(tesla_3)\n",
    "tesla_4 = df_to_series(tesla_4)\n",
    "tesla_5 = df_to_series(tesla_5)\n",
    "tesla_6 = df_to_series(tesla_6)\n",
    "tesla_7 = df_to_series(tesla_7)\n",
    "tesla_8 = df_to_series(tesla_8)\n",
    "tesla_9 = df_to_series(tesla_9)\n",
    "tesla_10 = df_to_series(tesla_10)\n",
    "tesla_11 = df_to_series(tesla_11)\n",
    "tesla_12 = df_to_series(tesla_12)\n",
    "tesla_13 = df_to_series(tesla_13)\n",
    "tesla_14 = df_to_series(tesla_14)\n",
    "tesla_15 = df_to_series(tesla_15)\n",
    "tesla_16 = df_to_series(tesla_16)\n",
    "tesla_17 = df_to_series(tesla_17)\n",
    "tesla_18 = df_to_series(tesla_18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e677fd2a",
   "metadata": {},
   "source": [
    "Creating full Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d685c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_a = pd.concat([tesla_1, tesla_2, tesla_3, tesla_4, tesla_5, tesla_6,\n",
    "                     tesla_7, tesla_8, tesla_9, tesla_10, tesla_11, tesla_12,\n",
    "                     tesla_13, tesla_14, tesla_15, tesla_16, tesla_17, tesla_18],axis = 0, join = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea8f606",
   "metadata": {},
   "source": [
    "Dropping Duplicates from Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc164099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67115"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tesla_General = tesla_a.drop_duplicates()\n",
    "len(Tesla_General)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e23a81a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0\n",
       "1527025892458999814    @testcranker @ITGuy1959 My solar is 100% off g...\n",
       "1527025892031086593    Boycott #Tesla #TeslaStock #ElonsProblems Vote...\n",
       "1527025884690993153    @dinodlz @cmclymer Tesla never would have surv...\n",
       "1527025878974271489    @MarketRebels @elwalvador It would be funny if...\n",
       "1527025852008976384    @RiceAndrew Right - it's just his nonsense pos...\n",
       "                                             ...                        \n",
       "1524803675050283013    Musk is a monster\\n\\nElon Musk praises Chinese...\n",
       "1524803303665717248    'Musk is well known for his disregard for labo...\n",
       "1524802474359545857    Elon Musk praises Chinese workers for â€˜burning...\n",
       "1524801906446458889    Elon Musk says Americans 'are trying to avoid ...\n",
       "1524801445932851209    Why are Tesla's employees getting injured cons...\n",
       "Length: 67115, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tesla_General"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24749363",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34611bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla = Tesla_General.apply(Series_Preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b6bad7",
   "metadata": {},
   "source": [
    "### Exporting Cleaned File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc3cccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla.to_csv('Data/Data-Cleaned/Tesla-Cleaned-67k')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
