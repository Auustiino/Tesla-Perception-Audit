{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "279828db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "705e35a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/Raw-Queried/Tesla-general-10K'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tesla_1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../Data/Raw-Queried/Tesla-general-10K\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m tesla_2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Data/Raw-Queried/Tesla-General-20K\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m tesla_3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Data/Raw-Queried/Tesla-General-6K\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/broke-the-other/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/broke-the-other/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/broke-the-other/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/broke-the-other/lib/python3.10/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/broke-the-other/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/broke-the-other/lib/python3.10/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/Raw-Queried/Tesla-general-10K'"
     ]
    }
   ],
   "source": [
    "tesla_1 = pd.read_csv('../Data/Raw-Queried/Tesla-general-10K')\n",
    "tesla_2 = pd.read_csv('../Data/Raw-Queried/Tesla-General-20K')\n",
    "tesla_3 = pd.read_csv('../Data/Raw-Queried/Tesla-General-6K')\n",
    "tesla_4 = pd.read_csv('../Data/Raw-Queried/Tesla-General-15K')\n",
    "tesla_5 = pd.read_csv('../Data/Raw-Queried/ElectricCars-General-10k')\n",
    "tesla_6 = pd.read_csv('../Data/Raw-Queried/Tesla-AI-1K')\n",
    "tesla_7 = pd.read_csv('../Data/Raw-Queried/Tesla-AutoPilot-1k')\n",
    "tesla_8 = pd.read_csv('../Data/Raw-Queried/Tesla-Batteries-1k')\n",
    "tesla_9 = pd.read_csv('../Data/Raw-Queried/Tesla-Batterys-1K')\n",
    "tesla_10 = pd.read_csv('../Data/Raw-Queried/Tesla-bot-1.5k')\n",
    "tesla_11 = pd.read_csv('../Data/Raw-Queried/Tesla-Cars-1K')\n",
    "# tesla_12 = pd.read_csv('Data/Raw-Queried/Tesla-cars-6K')\n",
    "# tesla_13 = pd.read_csv('Data/Raw-Queried/Tesla-Production-1K')\n",
    "# tesla_14 = pd.read_csv('Data/Raw-Queried/Tesla-solar-1K')\n",
    "# tesla_15 = pd.read_csv('Data/Raw-Queried/Tesla-stock-10k')\n",
    "# tesla_16 = pd.read_csv('Data/Raw-Queried/Tesla-truck-.5k')\n",
    "# tesla_17 = pd.read_csv('Data/Raw-Queried/Tesla-workers-1K')\n",
    "# tesla_18 = pd.read_csv('Data/Raw-Queried/Tesla-working_conds-.2K')\n",
    "# tesla_19 = pd.read_csv('Data/Raw-Queried/Tesla-Cars-7k')\n",
    "# tesla_20 = pd.read_csv('Data/Raw-Queried/Tesla-Environment-1k')\n",
    "# tesla_21 = pd.read_csv('Data/Raw-Queried/Tesla-FSD-1k')\n",
    "# tesla_22 = pd.read_csv('Data/Raw-Queried/Tesla-General-15k-2')\n",
    "# tesla_23 = pd.read_csv('Data/Raw-Queried/Tesla-General-15k-3')\n",
    "# tesla_24 = pd.read_csv('Data/Raw-Queried/Tesla-General-15k-4')\n",
    "# tesla_25 = pd.read_csv('Data/Raw-Queried/Tesla-General-25k-x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac92c24",
   "metadata": {},
   "source": [
    "### Function to turn all DataFrames from files into Series with User ID as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c81b4915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to turn 2 column df from csv files to 1 column series with user ID as index\n",
    "\n",
    "def df_to_series(df):\n",
    "    step1 = df.set_index('Unnamed: 0')\n",
    "    step2 = step1.squeeze()\n",
    "    return step2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a52e7",
   "metadata": {},
   "source": [
    "### Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accfb77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Series_Preprocessor(tweet):\n",
    "    stopWords = stopwords.words('english')\n",
    "    ps = PorterStemmer()\n",
    "    wnl = WordNetLemmatizer()\n",
    "\n",
    "        # helper function to change nltk's part of speech tagging to a wordnet format.\n",
    "    def pos_tagger(nltk_tag):\n",
    "        if nltk_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif nltk_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif nltk_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif nltk_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:         \n",
    "            return None\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#   Lowercase all \n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "#   Removing @ handles, links-- strip whitespace breaks and tabs\n",
    "    tweet = re.sub(r\"@\\w+|http\\S+\", \"\", tweet).strip().replace(\"\\r\", \"\").replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    \n",
    "    \n",
    "#   Tokenize,make list of words, removing punctuation and stopwords\n",
    "    tweet = [x for x in word_tokenize(tweet) if ((x.isalpha()) & (x not in stopWords)) ]\n",
    "    \n",
    "    \n",
    "#   Map part of speech tags to words and use words/tags to lemmatize accuratley\n",
    "    tweet = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tag(tweet))) \n",
    "    tweet = \" \".join([wnl.lemmatize(x[0], x[1]) for x in tweet if x[1] is not None])\n",
    "\n",
    "\n",
    "    return tweet "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f4535f",
   "metadata": {},
   "source": [
    "### Applying Function to set all User IDs as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45063dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_1 = df_to_series(tesla_1)\n",
    "tesla_2 = df_to_series(tesla_2)\n",
    "tesla_3 = df_to_series(tesla_3)\n",
    "tesla_4 = df_to_series(tesla_4)\n",
    "tesla_5 = df_to_series(tesla_5)\n",
    "tesla_6 = df_to_series(tesla_6)\n",
    "tesla_7 = df_to_series(tesla_7)\n",
    "tesla_8 = df_to_series(tesla_8)\n",
    "tesla_9 = df_to_series(tesla_9)\n",
    "tesla_10 = df_to_series(tesla_10)\n",
    "tesla_11 = df_to_series(tesla_11)\n",
    "tesla_12 = df_to_series(tesla_12)\n",
    "tesla_13 = df_to_series(tesla_13)\n",
    "tesla_14 = df_to_series(tesla_14)\n",
    "tesla_15 = df_to_series(tesla_15)\n",
    "tesla_16 = df_to_series(tesla_16)\n",
    "tesla_17 = df_to_series(tesla_17)\n",
    "tesla_18 = df_to_series(tesla_18)\n",
    "\n",
    "tesla_19 = df_to_series(tesla_19)\n",
    "tesla_20 = df_to_series(tesla_20)\n",
    "tesla_21 = df_to_series(tesla_21)\n",
    "tesla_22 = df_to_series(tesla_22)\n",
    "tesla_23 = df_to_series(tesla_23)\n",
    "tesla_24 = df_to_series(tesla_24)\n",
    "tesla_25 = df_to_series(tesla_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e677fd2a",
   "metadata": {},
   "source": [
    "Creating full Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d685c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_a = pd.concat([tesla_1, tesla_2, tesla_3, tesla_4, tesla_5, tesla_6,\n",
    "                     tesla_7, tesla_8, tesla_9, tesla_10, tesla_11, tesla_12,\n",
    "                     tesla_13, tesla_14, tesla_15, tesla_16, tesla_17, tesla_18, \n",
    "                     tesla_19, tesla_20, tesla_21, tesla_22, tesla_23, tesla_24, \n",
    "                     tesla_25],axis = 0, join = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea8f606",
   "metadata": {},
   "source": [
    "Dropping Duplicates from Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc164099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113671"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tesla_General = tesla_a.drop_duplicates()\n",
    "len(Tesla_General)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e23a81a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0\n",
       "1527025892458999814    @testcranker @ITGuy1959 My solar is 100% off g...\n",
       "1527025892031086593    Boycott #Tesla #TeslaStock #ElonsProblems Vote...\n",
       "1527025884690993153    @dinodlz @cmclymer Tesla never would have surv...\n",
       "1527025878974271489    @MarketRebels @elwalvador It would be funny if...\n",
       "1527025852008976384    @RiceAndrew Right - it's just his nonsense pos...\n",
       "                                             ...                        \n",
       "1527731732459438082    @DoctorJack16 You need to look again. Competit...\n",
       "1527731707058835456    Tesla has lost its crown jewel status in Cathi...\n",
       "1527731706907721730    @Yodadio3 @MairinSi @Nunyabizness32 @twrobinet...\n",
       "1527731695281119233    @d_w4y @SpokespersonCHN with strategic vision ...\n",
       "1527731676310388737    @ReneeAlida I’m waiting for the TESLA STOCKHOL...\n",
       "Length: 113671, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tesla_General"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24749363",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34611bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla = Tesla_General.apply(Series_Preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe4bad26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0\n",
       "1527025892458999814    solar grid run computer radio fridge entire ya...\n",
       "1527025892031086593     boycott tesla teslastock elonsproblems vote blue\n",
       "1527025884690993153    tesla never survive carbon offset implement de...\n",
       "1527025878974271489                 funny fanbase take profit sell tesla\n",
       "1527025852008976384    right nonsense position find sort hard believe...\n",
       "                                             ...                        \n",
       "1527731732459438082    need look competition get good plentiful redes...\n",
       "1527731707058835456    tesla lose crown jewel status cathie wood main...\n",
       "1527731706907721730    ya clearly go bank much cash stock downturn ca...\n",
       "1527731695281119233       strategic vision apple tesla prefer stay china\n",
       "1527731676310388737                       wait tesla stockholder lawsuit\n",
       "Length: 113671, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tesla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b6bad7",
   "metadata": {},
   "source": [
    "### Exporting Cleaned File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc3cccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla.to_csv('Data/Data-Cleaned/Tesla-Cleaned-113k')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "broke-the-other",
   "language": "python",
   "name": "broke-the-other"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
